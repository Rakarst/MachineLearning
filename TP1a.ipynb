{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Decision Trees and Clustering Techniques\n",
    "\n",
    "## *Aprendizagem Computacional - MEI | Computação Neuronal e Sistemas Difusos - MIEB*\n",
    "\n",
    "### by Catarina Silva and Marco Simões\n",
    "\n",
    "_\n",
    "\n",
    "This assignment will assess the students knowledge on the following Machine Learning topics:\n",
    "- Decision Trees\n",
    "- Clustering Techniques\n",
    "\n",
    "The assignment is split into two sub-assignments: 1-a) Decision Trees (first week) and 1-b) Clustering Techniques (second week).\n",
    "\n",
    "Students should implement their solutions and answering the questions directly in the notebooks, and submit both files together in Inforestudante before the deadline: *06/10/2021*\n",
    "\n",
    "## Conditions: \n",
    "- *Groups:* two elements of the same PL class\n",
    "- *Duration:* 2 weeks\n",
    "- *Workload:* 8h per student\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - a) Decision Trees\n",
    "\n",
    "Consider the depression dataset, from Agresti, A. (2019). _An introduction to categorical data analysis (2nd ed.). John Wiley & Sons._ This dataset is composed by evaluations of 335 patients during 3 phase treatment. We want to learn a decision tree that, given the attributes A - Diagnosis Severity (0: Mild, 1: Severe), B - Treatment Type (0: Standard, 1: New drug) and C - Follow Up Time (0: 1 week, 1: 2 weeks, 2: 4 weeks), predicts D - Depression Outcome (0: Normal, 1: Abnormal).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "... # TODO add extra imports if needed\n",
    "\n",
    "\n",
    "# load data\n",
    "data = pd.read_csv('depression.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Ex. 1\n",
    "Create a function `attr_probs( data, attr )` that, given the dataset (`data`) and a attribute id (`attr`), computes the percentage of cases with Abnormal treatment outcome (D) for each attribute *value*. The function should return a dictionary with the different attribute values as keys and the correspondent percentages as values. Example: `attr_probs( data, 'A')` -> returns `{0: 0.30, 1: 0.23}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTCOME = 'D'\n",
    "\n",
    "def attr_probs( data, attr):\n",
    "\n",
    "    probs = {}\n",
    "    unique_values = data[attr].unique()\n",
    "    \n",
    "    for val in unique_values:\n",
    "        selection = data.loc[data[attr] == int(val)]\n",
    "        probs[val] = round(selection[OUTCOME].sum() / selection.shape[0],2)\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.67, 1: 0.41}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_probs( data, 'A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "### Ex. 2\n",
    "Create a function `entropy( probs )` that, given a list probability values, returns the correspondent **entropy** value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy( probs ):\n",
    "    entropy = 0\n",
    "    for i in probs:\n",
    "        if(i!=0):\n",
    "            entropy+= -i*np.log2(i)\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "print(entropy([2/8, 0/8, 4/8, 2/8])) # should print 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Ex. 3 \n",
    "Create a function `gain( data, attr )` to compute the gain of an attribute. Make use of the functions developed in the previous exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain( data, attr ):\n",
    "    # TODO CODE HERE\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Ex. 4 \n",
    "\n",
    "Run the following code to compute the gain for the different attributes. In what does those results influence the design of the decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRS = ['A', 'B', 'C']\n",
    "for attr in ATTRS:\n",
    "    print('Gain {attr}: {gain:.2f}'.format(attr=attr, gain=gain(data, attr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "\n",
    "`TODO write answer here ...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Ex. 5\n",
    "\n",
    "Split the dataset into two sets (train set and test set), assigning randomly $70\\%$ of the cases to the train set and the remaining $30\\%$ to the test set. Use the `train_test_split` method from the `sklearn.model_selection` module, specifying the `random_state` with a value of $7$ for reproducibility purposes.\n",
    "\n",
    "Train a `DecisionTreeClassifier` (from the `sklearn.tree` module) using the training data. Enforce the use of the `entropy` criterion instead of the `gini` criterion. \n",
    "\n",
    "Resort to the function `export_text` from the `sklearn.tree` module to visualize the structure of the resulting tree. Are the results of **Ex. 4** congruent with the tree obtained here? Justify.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "\n",
    "`TODO write answer here ...`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Ex 6\n",
    "\n",
    "Looking for the structure of the tree printed, evaluate the following cases (by hand) and provide the outcome class for each case, as well as the path from the root to the leaf (meaning, provide the conditions it evaluated as true to reach that class).\n",
    "\n",
    "**Cases:**<p>\n",
    "c1 = (A=1, B=0, C=2)<p>\n",
    "c2 = (A=0, B=0, C=0)<p>\n",
    "c3 = (A=0, B=0, C=1)<p>\n",
    "c4 = (A=1, B=1, C=0)<p>\n",
    "\n",
    "\n",
    "**Example:**<p>\n",
    "case: cx = (A=1, B=1, C=1)<p>\n",
    "path: (C <= 1.5) --> (A > 0.5) --> (C > 0.5) --> (B > 0.5) --> class 1<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "\n",
    "case: c1 = (A=1, B=0, C=2)<p>\n",
    "path: `TODO write answer here ...`<p>\n",
    "_\n",
    "\n",
    "case: c2 = (A=0, B=0, C=0)<p>\n",
    "path: `TODO write answer here ...`<p>\n",
    "_\n",
    "\n",
    "case: c3 = (A=0, B=0, C=1)<p>\n",
    "path: `TODO write answer here ...`<p>\n",
    "_\n",
    "\n",
    "case: c4 = (A=1, B=1, C=0)<p>\n",
    "path: `TODO write answer here ...`<p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Ex. 7\n",
    "\n",
    "Apply the decision tree trained in the previous exercise to the test data. Compare the predicted labels to the true labels, generating a confusion matrix (you can use the `confusion_matrix` function of the `sklearn.metrics` module for that). Report the **percentage** of `True Positives, True Negatives, False Positives and False Negatives`, as well as the metrics `accuracy, precision, recall and f1-score`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Ex. 8\n",
    "Repeat the process of spliting the data, training the classifier and testing the classifier 100 times (use the values from 0 to 99 as `random_state` for the `train_test_split`function). Plot the accuracy across the 100 repetitions, reporting also its mean value and standard deviation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
